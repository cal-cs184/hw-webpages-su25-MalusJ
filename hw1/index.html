<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Yuanbo Jiang</div>

		
		<figure>
			<img src="lion.jpg" alt="Lion" style="width:50%"/>
			<figcaption>Project 1 Rasterizer</figcaption>
		</figure>

		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		
		<h2>Task 1: Drawing Single-Color Triangles</h2>
		Before working on rasterizing, I made sure that the triangles are consistent with its orientation, in this case making them all clockwise. So I check the coordinates and apply a test on them. This is done by calculating the signed area using the coordinates of each vertex. The formula is shown below:
		<p>\[ (x_1 - x_0)(y_2 - y_0) - (x_2 - x_0)(y_1 - y_0) \] </p>
		If the value is positive, the vertices are ordered clockwise.If the value is negative, the order is counterclockwise and the algorithm will swap two vertices to make it clockwise. 
		<p>After ensuring the same orientation, I turn the triangle into edge <b>vectors</b> for implementation purposes. Each side of triangle also becomes a vector. Vertices are represented as A, B, and C. Edges are are represented as AB, BC, and CA.
		Then we get the bounding box by calculating the min and max of these points coordinates. The value is taken floor/ceiling to make sure it does not miss anything. Then we apply the sampling method from lecture,<b>three lines test</b>, on each pixel within bounding box to determine whether it should be filled. I computed inward-facing normal vectors by taking the cross product of each edge with z-axis unit vector (0, 0, 1) to suuport the Three-Line Test.</p>

		<p>The three line test can be breaked down into 3 steps</p>
		<ul>
					<li>For each edge, subtract the edge's startubf vertex from the pixel to get directional vector.</li>
					<li>Take the dot product of the directional vector with the edge's inward-facing normal vector.</li>
					<li>If all three dot products are non-negative, that means the pixel lies inside the triangle.</li>
		</ul>
		<p>The assignement requires the algorithm to be no worse than checking every pixel within the bounding box. Since my algorithm is exactly the same approach, it meets the requirement. Extra credit not attempted</p>
		
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="demo1.png" width="400px"/>
				  <figcaption>Result</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="demo2.png" width="400px"/>
				  <figcaption>Result with inspector</figcaption>
				</td>
			  </tr>
			  
			</table>
		</div>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
		<p>Supersampling is a technique to improve visual quality of rasterized shapes. The algorithm can be break down into following step:</p>
		<ul>
					<li>Just like previous task, we determine the bounding box first.</li>
					<li>For each pixel inside the bounding box, the algorithm loops through a grid of subsamples, determined by the sqaure root of the sample rate.</li>
					<li>Apply the same three line test as before on each subsample to see whether it is inside the triangle</li>
					<li>If the subsample is inside the triangle, write the corlor value in its corresponding location.</li>
		</ul>
		<p>The idea behind supersampling can be seen as rendering in a higher resolution and scale down to the one we have. This is done by using <b>subsample grid</b> within each pixel. Instead of determining the color of a pixel from a single point, we divide it into subsamples. And the results from all subsamples in a pixel are averaged to determine the color. This approach is a useful tool to  remove the sawtooth feeling in the image and to eventually improve image's quality.</p>
		<p>To enable Antialiasing, I edited the size pf <b>sample_buffer</b> to adapt. And I modified <b>rasterize_triangle</b> looping method to cover the subsamples and apply the coverage test on them. Finally, I edited the <b>resolve_to_framebuffer</b> to average all subsamples for each pixel before getting the RGB value of the sample.</b></p>
		<div style="display: flex; justify-content: center; gap: 20px; align-items: center;">
			<div style="text-align: center;">
			<img src="super1.png" width="300px"/>
			<figcaption>Sample Rate 1</figcaption>
			</div>
		<div style="text-align: center;">
			<img src="super4.png" width="300px"/>
			<figcaption>Sample Rate 4</figcaption>
		</div>
		<div style="text-align: center;">
			<img src="super9.png" width="300px"/>
			<figcaption>Sample Rate 9</figcaption>
		</div>
		<div style="text-align: center;">
			<img src="super16.png" width="300px"/>
			<figcaption>Sample Rate 16</figcaption>
		</div>
		</div>
		<p> </p>
		
		
		<h2>Task 3: Transforms</h2>
		<p>I rotated cube man's arms and legs, and changed the color of its hair, forearm, leg, and clothes to match goku's clothes. The whole image is cube man using a spirit bomb.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="gokustick.png" width="400px"/>
				  <figcaption>Goku posture</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="goku.webp" width="400px"/>
				  <figcaption>Actual Goku</figcaption>
				</td>
			  </tr>
			  
			</table>
		</div>
		<h2>Task 4: Barycentric coordinates</h2>
		<p>The Barycentric Coordinates is a coordinate system of triangles that helps obtain smoothly varying values(color, depth, and texture) across surface. In this project, we use barycentric coordinates to interpolate colors between the triangle's three vertices, presenting a smoothly blend from one color to another.</p>
		<figure>
			<img src="rgb_triangle.png" alt="Color" style="width:50%"/>
			<figcaption>Barycentric Triangle</figcaption>
		</figure>
		<p>In the image above, the triangle with red, green and blue vertices is rasterized with a continuous blend between the three colors. Because color is computed through weights from each vertex. The weights sum to 1 and determine how much each color contribute to the result.</p>
		
		<figure>
			<img src="color1.png" alt="Color" style="width:50%"/>
			<figcaption>Barcentric Result Screenshot</figcaption>
		</figure>
		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		<p>When we do texture mapping, which is assigning a 2D image texture onto a 3D surface, the pixels typically coreesponds to a non-integer texture coordinates. And because textures' grid is discrete, it gives us a challenge to assign a color from these continuous coordinates.</p>
		<p>To solve this, <b>pixel sampling</b> is introduced. It helps us to get the proper coloring so it does not look pixelated. Here we have two methods: <b>Nearest Neighbor Sampling</b> and <b>Bilinear Interpolation Sampling</b>.</p>
		<ul>
					<li><b>Nearest Neighbor Sampling</b> is selecting the color that is closet to the given coordinate. The approach is considered fast but does not provide great quality.</li>
					<li><b>Bilinear Interpolation Sampling</b> uses weighted average of the four texels around the given coorginate. This approach would provide better and smoother result than Nearest neighbor sampling but would require more computations.</li>
					<li>The reason why bilinear interpolation sampling provide better result than nearest neighbor sampling is that it samples not just one pixel but a weighted average from all its surrounded pixel to get the best corresponded color.</li>
		</ul>
		<div style="display: flex; justify-content: center; gap: 20px; align-items: center;">
			<div style="text-align: center;">
			<img src="near1.png" width="300px"/>
			<figcaption>Nearest Sampling 1 Sample per Pixel</figcaption>
			</div>
		<div style="text-align: center;">
			<img src="near16.png" width="300px"/>
			<figcaption>Nearest Sampling 16 Sample per Pixel</figcaption>
		</div>
		<div style="text-align: center;">
			<img src="bi1.png" width="300px"/>
			<figcaption>Bilinear Sampling 1 Sample per Pixel</figcaption>
		</div>
		<div style="text-align: center;">
			<img src="bi16.png" width="300px"/>
			<figcaption>Bilinear Sampling 16 Sample per Pixel</figcaption>
		</div>
		</div>
		<p>Nearest Sampling with 1 supersample per pixel is the worst since it has strong aliasing, edges appear to be very jagged. Switching to Bilinear increased texel and surface quality and the color transitions appear to be more natural. And switching from 1 supersamplee to 16 supersample increased the smoothness of the edges and Bilinear and 16 supersamples produce the best result whereas Nearest and 1 supersample produced the worst.</p>
		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
			<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="sample.png" width="400px"/>
				  <figcaption>Without level sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="sample2.png" width="400px"/>
				  <figcaption>With level sampling</figcaption>
				</td>
			  </tr>
			  
			</table>
		</div>
		<p>In texture mapping, there is a challenge when the screen pixel has a large area in the texture. For example, when viewing a textured surface from far distance would cause aliasing(image above). So to solve this, <b>level sampling </b> is introduced. The approach compute lower-resolution of the texture and select the best one based on different situation. The lower resolution texture is called <b>mipmaps</b>. So when a pixel cover a larger part on the texture, a lower reolution mimap is used to avoid sampling too many texels causing aliasing. The level sampling approach prevent aliasing, improve textures and improve performance(sometimes).</p>
		<p>In this project, the implementation is done by computing the difference in UV coordinates beteen a sample and samples around it. Then the difference is used to estimate the screen sampling rate in texture space. The data is passed to function <b>get_level</b> to get the best mipmap level to use for the sample.</p>
		<div style="display: flex; justify-content: center; gap: 20px; align-items: center;">
			<div style="text-align: center;">
			<img src="0p.png" width="300px"/>
			<figcaption>L_ZERO and P_Nearest</figcaption>
			</div>
		<div style="text-align: center;">
			<img src="0l.png" width="300px"/>
			<figcaption>L_ZERO and P_Linear</figcaption>
		</div>
		<div style="text-align: center;">
			<img src="pp.png" width="300px"/>
			<figcaption>L_Nearest and P_Nearest</figcaption>
		</div>
		<div style="text-align: center;">
			<img src="ll.png" width="300px"/>
			<figcaption>L_Nearest and P_Linear</figcaption>
		</div>
		</div>
		<ul>
		<li>Zero level sampling with nearest pixel sampliing always use the original texture and does not use mipmaps. So it appear to be most jagged. </li>
			<li>Adding Bilinear pixel sampling to zero level sampling would help with smoothness in close range. But would still see some aliasing far away.</li>
		<li>Nearest level sampling with nearest pixel sampling would add mip level choice to adapt better in different sample but still got rough edges. </li>
		<li>Nearest level sampling with bilinear pixel sampling produce the best quality and the least aliasing.</li>
		</ul>
		<p>Using level sampling would improve visual quality and adaptability. Sometimes it improves performance speed. But it always increases the memory usage. Using bilinear pixel sampling would always produce a better quality than nearest sampling method but it always comes with a higher cost in computation.</p>
		</div>
		</div>
		
	
		</div>
	</body>
</html>